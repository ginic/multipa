{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a468115",
   "metadata": {},
   "source": [
    "# By-phone error rates: Buckeye test set\n",
    "This computes and compares error rates at the phone level across different models. This helps us understand which phones are most frequently mistaken by the models we're interested in. Conversely, can also see which phones we're performing well on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import ipatok\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from phonecodes import phonecode_tables\n",
    "import seaborn as sns\n",
    "\n",
    "from multipa.evaluation import ModelEvaluator, PREDICTION_KEY\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "DETAILED_EVAL_PATH = Path(\"../data/evaluation_results/detailed_predictions/\")\n",
    "# These are the models we're actually interested in evaluating in detail\n",
    "DETAILED_EVAL_CSVS = [\n",
    "    # Models trained on full 20K samples (full dataset but gender balanced)\n",
    "    \"data_models_train_duration_20000_samples_1_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    \"data_models_train_duration_20000_samples_2_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    \"data_models_train_duration_20000_samples_3_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    \"data_models_train_duration_20000_samples_4_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    \"data_models_train_duration_20000_samples_5_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    # Models trained on entire dataset\n",
    "    \"ginic_full_dataset_train_1_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    \"ginic_full_dataset_train_2_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    \"ginic_full_dataset_train_3_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    \"ginic_full_dataset_train_4_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    \"ginic_full_dataset_train_5_wav2vec2-large-xlsr-53-buckeye-ipa_detailed_predictions.csv\",\n",
    "    # Third party comparison models\n",
    "    #\"openai_whisper-large-v3-turbo_to_epitran_detailed_predictions.csv\",\n",
    "    \"openai_whisper-medium.en_to_epitran_detailed_predictions.csv\",\n",
    "    \"allosaurus_eng2102_eng_detailed_predictions.csv\",\n",
    "    #\"facebook_wav2vec2-xlsr-53-espeak-cv-ft_detailed_predictions.csv\",\n",
    "    \"facebook_wav2vec2-lv-60-espeak-cv-ft_detailed_predictions.csv\",\n",
    "    \"ctaguchi_wav2vec2-large-xlsr-japlmthufielta-ipa1000-ns_detailed_predictions.csv\"\n",
    "]\n",
    "\n",
    "REFERENCE_COL = \"ipa\"\n",
    "\n",
    "VALID_BUCKEYE_PHONES = set(phonecode_tables._buckeye2ipa.values())\n",
    "\n",
    "# This doesn't include all the nasalized vowels, only the ones that we computed the Pillai scores for\n",
    "BUCKEYE_VOWELS = set([\"ɑ\", \"æ\", \"ʌ\", \"ɔ\", \"aʊ\", \"aɪ\", \"ɛ\", \"ɹ̩\", \"eɪ\", \"ɪ\", \"i\", \"oʊ\", \"ɔɪ\", \"ʊ\", \"u\", \"æ̃\", \"ɔ̃\",\n",
    "                  \"ə̃\", \"ĩ\", \"ẽɪ̃\", \"õʊ̃\", \"ãɪ̃\", \"ɑ̃\", \"ũ\", \"ɾ̃\", \"ə\", \"ɛ̃\", \"ʊ̃\", \"ãʊ̃\", \"ʌ̃\", \"ɪ̃\", \"ɹ̩̃\", \"ɔ̃ɪ̃\"])\n",
    "\n",
    "BUCKEYE_CONSONANTS = VALID_BUCKEYE_PHONES - BUCKEYE_VOWELS\n",
    "\n",
    "# I'm just being picky about plot colors\n",
    "HUE_ORDER = [\"full_dataset_train\", \"train_duration_20000_samples\", \"openai_whisper-medium.en_to_epitran\", \"allosaurus_eng2102_eng\", \"facebook_wav2vec2-lv-60-espeak-cv-ft\", \"ctaguchi_wav2vec2-large-xlsr-japlmthufielta-ipa1000-ns\"]\n",
    "\n",
    "HUE_ORDER_INDEX = {key: i for i, key in enumerate(HUE_ORDER)}\n",
    "\n",
    "PALETTE = \"colorblind\"\n",
    "\n",
    "sns.set_palette(PALETTE)\n",
    "\n",
    "def diphthong_merge(t1, t2, dipthongs):\n",
    "    \"\"\"For merge detected diphthongs in predicted output when using ipatok.tokenise\"\"\"\n",
    "    if t1 + t2 in dipthongs:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Use for Buckeye tokenization for convenience\n",
    "buckeye_merge_func = lambda x,y: diphthong_merge(x, y, VALID_BUCKEYE_PHONES)\n",
    "\n",
    "def get_model_group(model_name):\n",
    "    for p in [\"train_duration_20000_samples\", \"full_dataset_train\"]:\n",
    "        if model_name.startswith(p):\n",
    "            return p\n",
    "    return model_name\n",
    "\n",
    "def compute_error_rate_confidence_intervals_df(error_rate_df, count_df, error_rate_join_key, count_join_key, error_rate_col, count_col, interval_const = 1.96):\n",
    "    \"\"\"Computes error rates for each vowel with a confidence interval of according to\n",
    "    https://machinelearningmastery.com/report-classifier-performance-confidence-intervals/\n",
    "    The default settings give a confidence interval of 95%.\n",
    "    \"\"\"\n",
    "    joined_df = pd.merge(error_rate_df, count_df, left_on=error_rate_join_key, right_on=count_join_key, how=\"inner\")\n",
    "    error_series = joined_df[error_rate_col]\n",
    "    joined_df[\"confidence_interval\"] = interval_const * np.sqrt( (error_series *(1-error_series))/ joined_df[count_col])\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in model results and re-generate comparison metrics\n",
    "MODEL_EVALUATOR = ModelEvaluator(tokenise_options={\"diphthongs\":True, \"merge\":buckeye_merge_func})\n",
    "\n",
    "for csv in DETAILED_EVAL_CSVS:\n",
    "    print(\"Processing\", csv)\n",
    "    if csv.startswith(\"data_models_train_duration\"):\n",
    "        model_name = re.search(r'train_duration_20000_samples_[1-5]', csv).group()\n",
    "    elif csv.startswith(\"ginic_full_dataset_train\"):\n",
    "        model_name = re.search(r'full_dataset_train_[1-5]', csv).group()\n",
    "    else:\n",
    "        model_name = csv.removesuffix(\"_detailed_predictions.csv\")\n",
    "    model_results = pd.read_csv(\n",
    "            DETAILED_EVAL_PATH / csv,\n",
    "            dtype={PREDICTION_KEY: str, REFERENCE_COL: str},\n",
    "            keep_default_na=False\n",
    "        )\n",
    "    latest_ref_col = model_results[REFERENCE_COL]\n",
    "    MODEL_EVALUATOR.eval_edit_distances(model_name, model_results[PREDICTION_KEY], latest_ref_col, compute_by_token_error_rates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9235ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check token counts against actual vocabulary\n",
    "# The invalid token warnings are harmless, it's just removing some \"NOISE\" and disfluency markers that snuck through\n",
    "# data preprocessing, but don't affect training\n",
    "final_token_counts = {t:0 for t in VALID_BUCKEYE_PHONES}\n",
    "\n",
    "tokens = []\n",
    "for ref in latest_ref_col:\n",
    "    tokens.extend(ipatok.tokenise(ref, diphthongs=True, merge = buckeye_merge_func))\n",
    "\n",
    "test_token_counts = collections.Counter(tokens)\n",
    "final_token_counts.update(test_token_counts)\n",
    "\n",
    "for t in list(final_token_counts.keys()):\n",
    "    if t not in VALID_BUCKEYE_PHONES:\n",
    "        print(\"REMOVING INVALID TOKEN:\", t, t.encode(\"unicode-escape\"))\n",
    "        del final_token_counts[t]\n",
    "\n",
    "token_counts_df = pd.DataFrame.from_records(\n",
    "        list(final_token_counts.items()),\n",
    "        columns=[\"phone\", \"counts\"]).sort_values(\"counts\", ascending=False)\n",
    "\n",
    "display(token_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2892751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Munge data into dataframe format for analysis\n",
    "records = []\n",
    "for model_name, eval_results in MODEL_EVALUATOR.results_to_write.items():\n",
    "    for phone, err_rate in eval_results[MODEL_EVALUATOR.by_token_error_rates].items():\n",
    "        if phone in VALID_BUCKEYE_PHONES:\n",
    "            records.append((model_name, phone, err_rate))\n",
    "\n",
    "all_error_rates_df = pd.DataFrame.from_records(records, columns=[\"model_name\", \"phone\", \"err_rate\"])\n",
    "all_error_rates_df[\"model_group\"] = all_error_rates_df[\"model_name\"].apply(get_model_group)\n",
    "\n",
    "all_error_rates_df = compute_error_rate_confidence_intervals_df(all_error_rates_df,token_counts_df, \"phone\", \"phone\", \"err_rate\", \"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_error_rates_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22961a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_rates_by_phone_and_model(dataframe, groupby_key, xlabel=\"Phone\", ylabel=\"Normalized Error Rate\", title=\"Error rates by phone on the Buckeye test set\", fontsize=14, use_confidence_intervals=False, phone_col=\"phone\", err_rate_col=\"err_rate\", confidence_interval_col=\"confidence_interval\", figsize=(25, 4), legend_title=\"Experiment group/Model\", palette=PALETTE, hue_order = HUE_ORDER):\n",
    "    group_order = dataframe.groupby(phone_col)[err_rate_col].min().sort_values()\n",
    "    tmp_df = dataframe.copy(deep=True)\n",
    "    tmp_df[\"sort_order\"] = tmp_df[phone_col].map(group_order)\n",
    "    tmp_df = tmp_df.sort_values('sort_order')\n",
    "    if use_confidence_intervals:\n",
    "        tmp_df[\"upper\"] = tmp_df[err_rate_col] + tmp_df[confidence_interval_col]\n",
    "        tmp_df[\"lower\"] = tmp_df[err_rate_col] - tmp_df[confidence_interval_col]\n",
    "        fig, g = plt.subplots(figsize=figsize)\n",
    "        palette = sns.color_palette(palette)\n",
    "        for i, group in enumerate(hue_order):\n",
    "            group_df = tmp_df[tmp_df[groupby_key] == group]\n",
    "            color = palette[i]\n",
    "            x = group_df[phone_col]\n",
    "            g.plot(x, group_df[err_rate_col], label=group, color=color)\n",
    "            g.plot(x, group_df[\"lower\"], color=color, alpha=0.2)\n",
    "            g.plot(x, group_df[\"upper\"], color=color, alpha=0.2)\n",
    "            g.fill_between(x, group_df[\"lower\"], group_df[\"upper\"], alpha=0.2)\n",
    "\n",
    "    else:\n",
    "        plt.figure(figsize=figsize)\n",
    "        g = sns.lineplot(data = tmp_df, y=err_rate_col, x = phone_col, hue=groupby_key, style=groupby_key, palette=palette, hue_order=hue_order)\n",
    "\n",
    "    g.set_xlabel(xlabel, fontsize=fontsize)\n",
    "    g.set_ylabel(ylabel, fontsize=fontsize)\n",
    "    g.set_title(title, fontsize=fontsize)\n",
    "    g.tick_params(labelsize=fontsize)\n",
    "    g.set_ylim(0, 1)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left',fontsize=fontsize, title=legend_title, title_fontsize=fontsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7937a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "consonant_df = all_error_rates_df[all_error_rates_df[\"phone\"].isin(BUCKEYE_CONSONANTS)]\n",
    "plot_error_rates_by_phone_and_model(consonant_df, \"model_group\", title=\"Error rates for consonants on the Buckeye test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09128c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_df = all_error_rates_df[all_error_rates_df[\"phone\"].isin(BUCKEYE_VOWELS)]\n",
    "plot_error_rates_by_phone_and_model(vowel_df, \"model_group\", title=\"Error rates for vowels on the Buckeye test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_models = all_error_rates_df[all_error_rates_df[\"model_group\"].isin([\"train_duration_20000_samples\", \"full_dataset_train\"])]\n",
    "model_orders = [f\"train_duration_20000_samples_{i}\" for i in range(1, 6)] + [f\"full_dataset_train_{i}\" for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b538a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_models_consonants = our_models[our_models[\"phone\"].isin(BUCKEYE_CONSONANTS)]\n",
    "plot_error_rates_by_phone_and_model(our_models_consonants, \"model_name\", title=\"AutoIPA model error rates for consonants on the Buckeye test set\\nwith confidence intervals\", use_confidence_intervals=True, hue_order = model_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce42a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_rates_by_phone_and_model(our_models_consonants, \"model_name\", title=\"AutoIPA model error rates for consonants on the Buckeye test set\", hue_order = model_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e54049",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_models_vowels = our_models[our_models[\"phone\"].isin(BUCKEYE_VOWELS)]\n",
    "plot_error_rates_by_phone_and_model(our_models_vowels, \"model_name\", title=\"AutoIPA model error rates for vowels on the Buckeye test set\\nwith confidence intervals\", use_confidence_intervals=True, hue_order = model_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf329e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_rates_by_phone_and_model(our_models_vowels, \"model_name\", title=\"AutoIPA model error rates for vowels on the Buckeye test set\", hue_order = model_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119976b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_rates_by_phone_and_model(our_models_consonants, \"model_group\", title=\"Error rates for consonants on the Buckeye test\\naveraged across AutoIPA experiment groups\", hue_order=[\"full_dataset_train\", \"train_duration_20000_samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_rates_by_phone_and_model(our_models_vowels, \"model_group\", title=\"Error rates for vowels on the Buckeye test\\naveraged across AutoIPA experiment groups\", hue_order=[\"full_dataset_train\", \"train_duration_20000_samples\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
